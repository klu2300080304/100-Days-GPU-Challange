{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WiXyXlPZKY3"
      },
      "outputs": [],
      "source": [
        "%%writefile vector_add.cu\n",
        "\n",
        "\n",
        "#include <iostream>\n",
        "#include <cmath>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void LayerNorm(const float* A, float* B, int rows, int cols) {\n",
        "    // Calculate row index\n",
        "    int row = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < rows) {\n",
        "        // Use shared memory for row-wise computation\n",
        "        extern __shared__ float shared[];\n",
        "        float* row_data = shared;\n",
        "\n",
        "        // Copy row data to shared memory\n",
        "        for (int col = threadIdx.y; col < cols; col += blockDim.y) {\n",
        "            row_data[col] = A[row * cols + col];\n",
        "        }\n",
        "        __syncthreads();\n",
        "\n",
        "        // Compute mean\n",
        "        float mean = 0.0f;\n",
        "        for (int col = 0; col < cols; col++) {\n",
        "            mean += row_data[col];\n",
        "        }\n",
        "        mean /= cols;\n",
        "\n",
        "        // Compute variance\n",
        "        float variance = 0.0f;\n",
        "        for (int col = 0; col < cols; col++) {\n",
        "            variance += (row_data[col] - mean) * (row_data[col] - mean);\n",
        "        }\n",
        "        variance /= cols;\n",
        "        float stddev = sqrtf(variance + 1e-7);\n",
        "\n",
        "        // Normalize\n",
        "        for (int col = threadIdx.y; col < cols; col += blockDim.y) {\n",
        "            B[row * cols + col] = (row_data[col] - mean) / stddev;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int rows = 10, cols = 10;\n",
        "    float *A, *B;\n",
        "\n",
        "    // Allocate host memory\n",
        "    A = (float*)malloc(rows * cols * sizeof(float));\n",
        "    B = (float*)malloc(rows * cols * sizeof(float));\n",
        "\n",
        "    // Initialize input matrix\n",
        "    for (int i = 0; i < rows; i++) {\n",
        "        for (int j = 0; j < cols; j++) {\n",
        "            A[i * cols + j] = static_cast<float>(rand()) / RAND_MAX;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    float *d_a, *d_b;\n",
        "    cudaMalloc(&d_a, rows * cols * sizeof(float));\n",
        "    cudaMalloc(&d_b, rows * cols * sizeof(float));\n",
        "\n",
        "    // Copy data to device\n",
        "    cudaMemcpy(d_a, A, rows * cols * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch kernel\n",
        "    int blocksize = 256;\n",
        "    int gridsize = (rows + blocksize - 1) / blocksize;\n",
        "    size_t shared_memory_size = cols * sizeof(float);\n",
        "    LayerNorm<<<gridsize, blocksize, shared_memory_size>>>(d_a, d_b, rows, cols);\n",
        "\n",
        "    // Synchronize device\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(B, d_b, rows * cols * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print results\n",
        "    printf(\"A:\\n\");\n",
        "    for (int i = 0; i < rows; i++) {\n",
        "        for (int j = 0; j < cols; j++) {\n",
        "            printf(\"%.2f \", A[i * cols + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"\\nB:\\n\");\n",
        "    for (int i = 0; i < rows; i++) {\n",
        "        for (int j = 0; j < cols; j++) {\n",
        "            printf(\"%.2f \", B[i * cols + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    free(A);\n",
        "    free(B);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with the specified architecture\n",
        "!nvcc vector_add.cu -o vector_add -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "# Run the executable\n",
        "!./vector_add"
      ],
      "metadata": {
        "id": "1bTd8PnVZS9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_x4nwRD8ZYQu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}