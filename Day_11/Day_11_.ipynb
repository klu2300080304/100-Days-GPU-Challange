{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ED5v7KLROtm0"
      },
      "outputs": [],
      "source": [
        "%%writefile vector_add.cu\n",
        "\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "define CUDA_CHECK(call) do { \\\n",
        "    cudaError_t err = call; \\\n",
        "    if (err != cudaSuccess) { \\\n",
        "        fprintf(stderr, \"CUDA error in %s:%d: %s\\n\", __FILE__, __LINE__, \\\n",
        "                cudaGetErrorString(err)); \\\n",
        "        exit(EXIT_FAILURE); \\\n",
        "    } \\\n",
        "} while(0)\n",
        "\n",
        "__global__ void ELL_kernel(const float* A, const float* X, float* data_ell,\n",
        "                           int* indices_ell, float* data_coo, int* row_coo,\n",
        "                           int* col_coo, float* output_matrix, const int threshold,\n",
        "                           const int N, const int M, int* global_coo_counter) {\n",
        "    int row = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (row >= N) return;\n",
        "\n",
        "    int counter = 0;\n",
        "\n",
        "    // Process row\n",
        "    for (int col = 0; col < M; ++col) {\n",
        "        float val = A[row * M + col];\n",
        "        if (val != 0) {\n",
        "            if (counter < threshold) {\n",
        "                // ELL format storage\n",
        "                data_ell[counter * N + row] = val;\n",
        "                indices_ell[counter * N + row] = col;\n",
        "                counter++;\n",
        "            } else {\n",
        "                // COO format storage\n",
        "                int coo_index = atomicAdd(global_coo_counter, 1);  // Atomic global counter\n",
        "                data_coo[coo_index] = val;\n",
        "                row_coo[coo_index] = row;\n",
        "                col_coo[coo_index] = col;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Fill unused ELL slots with zeros\n",
        "    for (int i = counter; i < threshold; ++i) {\n",
        "        data_ell[i * N + row] = 0;\n",
        "        indices_ell[i * N + row] = -1;\n",
        "    }\n",
        "\n",
        "    // Matrix-vector multiplication using ELL format\n",
        "    float acc = 0.0f;\n",
        "    for (int p = 0; p < threshold; ++p) {\n",
        "        int index = indices_ell[p * N + row];\n",
        "        if (index != -1) {\n",
        "            acc += data_ell[p * N + row] * X[index];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Add COO contribution\n",
        "    for (int i = 0; i < *global_coo_counter; ++i) {\n",
        "        if (row_coo[i] == row) {  // Verify this COO element belongs to the current row\n",
        "            acc += data_coo[i] * X[col_coo[i]];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    output_matrix[row] = acc;\n",
        "\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 1000;        // Rows\n",
        "    const int M = 1000;        // Columns\n",
        "    const int threshold = 20; // Threshold for ELL storage\n",
        "\n",
        "    // Host arrays - using dynamic allocation\n",
        "    float* A = new float[N * M];\n",
        "    float* data_ell = new float[N * threshold]();  // Initialize to zero\n",
        "    float* data_coo = new float[N * M]();\n",
        "    int* indices_ell = new int[N * threshold]();\n",
        "    int* row_coo = new int[N * M]();\n",
        "    int* col_coo = new int[N * M]();\n",
        "    float* X = new float[M];\n",
        "    float* output_matrix = new float[N];\n",
        "int* d_global_coo_counter;\n",
        "CUDA_CHECK(cudaMalloc(&d_global_coo_counter, sizeof(int)));\n",
        "CUDA_CHECK(cudaMemset(d_global_coo_counter, 0, sizeof(int)));  // Initialize to 0\n",
        "    // Initialize matrix A and vector X\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < M; j++) {\n",
        "            A[i * M + j] = (i + j) % 3 == 0 ? i + j : 0;\n",
        "        }\n",
        "    }\n",
        "    for (int i = 0; i < M; i++) {\n",
        "        X[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    // Device pointers\n",
        "    float *d_A, *d_X, *d_data_ell, *d_data_coo, *d_output_matrix;\n",
        "    int *d_indices_ell, *d_row_coo, *d_col_coo;\n",
        "\n",
        "    // Allocate device memory with error checking\n",
        "    CUDA_CHECK(cudaMalloc(&d_A, N * M * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_X, M * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_data_ell, N * threshold * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_data_coo, N * M * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_indices_ell, N * threshold * sizeof(int)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_row_coo, N * M * sizeof(int)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_col_coo, N * M * sizeof(int)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_output_matrix, N * sizeof(float)));\n",
        "\n",
        "    // Copy data to device\n",
        "    CUDA_CHECK(cudaMemcpy(d_A, A, N * M * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_X, X, M * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    // Get device properties\n",
        "    int device;\n",
        "    cudaGetDevice(&device);\n",
        "    cudaDeviceProp deviceProp;\n",
        "    cudaGetDeviceProperties(&deviceProp, device);\n",
        "\n",
        "    // Configure kernel launch parameters\n",
        "    int block_size = 256;  // Use a reasonable block size\n",
        "    int num_blocks = (N + block_size - 1) / block_size;\n",
        "\n",
        "    // Setup timing\n",
        "    cudaEvent_t start, stop;\n",
        "    CUDA_CHECK(cudaEventCreate(&start));\n",
        "    CUDA_CHECK(cudaEventCreate(&stop));\n",
        "\n",
        "    // Record start time\n",
        "    CUDA_CHECK(cudaEventRecord(start));\n",
        "\n",
        "    // Launch kernel\n",
        "    ELL_kernel<<<num_blocks, block_size>>>(d_A, d_X, d_data_ell, d_indices_ell,\n",
        "                                         d_data_coo, d_row_coo, d_col_coo,\n",
        "                                         d_output_matrix, threshold, N, M,d_global_coo_counter);\n",
        "\n",
        "    // Check for kernel launch errors\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "    // Record stop time\n",
        "    CUDA_CHECK(cudaEventRecord(stop));\n",
        "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&milliseconds, start, stop));\n",
        "    std::cout << \"CUDA kernel time: \" << milliseconds / 1000.0 << \" seconds\" << std::endl;\n",
        "\n",
        "    // Copy results back to host\n",
        "    CUDA_CHECK(cudaMemcpy(data_ell, d_data_ell, N * threshold * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    CUDA_CHECK(cudaMemcpy(data_coo, d_data_coo, N * M * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    CUDA_CHECK(cudaMemcpy(indices_ell, d_indices_ell, N * threshold * sizeof(int), cudaMemcpyDeviceToHost));\n",
        "    CUDA_CHECK(cudaMemcpy(row_coo, d_row_coo, N * M * sizeof(int), cudaMemcpyDeviceToHost));\n",
        "    CUDA_CHECK(cudaMemcpy(col_coo, d_col_coo, N * M * sizeof(int), cudaMemcpyDeviceToHost));\n",
        "    CUDA_CHECK(cudaMemcpy(output_matrix, d_output_matrix, N * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Clean up events\n",
        "    CUDA_CHECK(cudaEventDestroy(start));\n",
        "    CUDA_CHECK(cudaEventDestroy(stop));\n",
        "    // Copy global_coo_counter back to host to verify the number of COO elements\n",
        "int h_global_coo_counter;\n",
        "CUDA_CHECK(cudaMemcpy(&h_global_coo_counter, d_global_coo_counter, sizeof(int), cudaMemcpyDeviceToHost));\n",
        "for (int i = 0; i < 10; ++i) {\n",
        "    std::cout << \"COO[\" << i << \"]: val = \" << data_coo[i] << \", row = \" << row_coo[i] << \", col = \" << col_coo[i] << std::endl;\n",
        "}\n",
        "\n",
        "FILE *output_file = fopen(\"cuda_results.txt\", \"w\");\n",
        "if (output_file == nullptr) {\n",
        "    std::cerr << \"Failed to open output file!\" << std::endl;\n",
        "    return EXIT_FAILURE;\n",
        "}\n",
        "for (int i = 0; i < N; i++) {\n",
        "    fprintf(output_file, \"%.10f\\n\", output_matrix[i]);\n",
        "}\n",
        "fclose(output_file);\n",
        "std::cout << \"Wrote \" << N << \" values to cuda_results.txt\" << std::endl;  // Debugging line\n",
        "\n",
        "\n",
        "\n",
        "    // Free device memory\n",
        "    CUDA_CHECK(cudaFree(d_A));\n",
        "    CUDA_CHECK(cudaFree(d_X));\n",
        "    CUDA_CHECK(cudaFree(d_data_ell));\n",
        "    CUDA_CHECK(cudaFree(d_data_coo));\n",
        "    CUDA_CHECK(cudaFree(d_indices_ell));\n",
        "    CUDA_CHECK(cudaFree(d_row_coo));\n",
        "    CUDA_CHECK(cudaFree(d_col_coo));\n",
        "    CUDA_CHECK(cudaFree(d_output_matrix));\n",
        "\n",
        "    // Free host memory\n",
        "    delete[] A;\n",
        "    delete[] data_ell;\n",
        "    delete[] data_coo;\n",
        "    delete[] indices_ell;\n",
        "    delete[] row_coo;\n",
        "    delete[] col_coo;\n",
        "    delete[] X;\n",
        "    delete[] output_matrix;\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with the specified architecture\n",
        "!nvcc vector_add.cu -o vector_add -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "# Run the executable\n",
        "!./vector_add"
      ],
      "metadata": {
        "id": "zAae6POCPAaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_hD1_Na1VgyW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}