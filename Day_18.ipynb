{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgHjWIJglPgR"
      },
      "outputs": [],
      "source": [
        "%%writefile vector_add.cu\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main() {\n",
        "    cublasHandle_t handle;\n",
        "    cublasCreate(&handle);\n",
        "\n",
        "    int M = 2, N = 3, K = 4;\n",
        "    float *h_A, *h_B, *h_C;\n",
        "    h_A = (float *)malloc(M * K * sizeof(float));\n",
        "    h_B = (float *)malloc(K * N * sizeof(float));\n",
        "    h_C = (float *)malloc(M * N * sizeof(float));\n",
        "\n",
        "    for (int i = 0; i < M; i++)\n",
        "        for (int j = 0; j < K; j++)\n",
        "            h_A[i * K + j] = i + j;\n",
        "\n",
        "    for (int i = 0; i < K; i++)\n",
        "        for (int j = 0; j < N; j++)\n",
        "            h_B[i * N + j] = i + j;\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, M * K * sizeof(float));\n",
        "    cudaMalloc(&d_B, K * N * sizeof(float));\n",
        "    cudaMalloc(&d_C, M * N * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, M * K * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, K * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    const float alpha = 1.0f, beta = 0.0f;\n",
        "    cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N,\n",
        "                M, N, K, &alpha,\n",
        "                d_A, M, d_B, K,\n",
        "                &beta, d_C, M);\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, M * N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Matrix A:\\n\");\n",
        "    for (int i = 0; i < M; i++) {\n",
        "        for (int j = 0; j < K; j++) {\n",
        "            printf(\"%f \", h_A[i * K + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"Matrix B:\\n\");\n",
        "    for (int i = 0; i < K; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%f \", h_B[i * N + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"Matrix C = A * B:\\n\");\n",
        "    for (int i = 0; i < M; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%f \", h_C[i + j * M]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    free(h_A); free(h_B); free(h_C);\n",
        "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "    cublasDestroy(handle);\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with the specified architecture\n",
        "!nvcc vector_add.cu -o vector_add -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "# Run the executable\n",
        "!./vector_add"
      ],
      "metadata": {
        "id": "CM-axyrmlhCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A_5V42gplmqm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}