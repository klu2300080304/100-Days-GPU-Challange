{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf6I_ob5BLbz"
      },
      "outputs": [],
      "source": [
        "%%writefile vector_add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 1024  // Number of elements\n",
        "#define ETA 0.5f // Larger learning rate\n",
        "\n",
        "// Mirror Maps\n",
        "#define EUCLIDEAN         0  // Standard gradient descent\n",
        "#define NEGATIVE_ENTROPY  1  // Exponentiated gradient descent\n",
        "#define LOG_BARRIER       2  // Positive orthant\n",
        "\n",
        "__global__ void mirror_descent(float *x, float *grad, float eta, int mirror_map, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i >= n) return;\n",
        "\n",
        "    float new_x = x[i];\n",
        "\n",
        "    switch (mirror_map) {\n",
        "        case EUCLIDEAN:\n",
        "            new_x = x[i] - eta * grad[i];\n",
        "            break;\n",
        "\n",
        "        case NEGATIVE_ENTROPY:\n",
        "            new_x = x[i] * expf(-eta * grad[i]); // Ensure updates are visible\n",
        "            break;\n",
        "\n",
        "        case LOG_BARRIER:\n",
        "            new_x = x[i] / (1.0f + eta * grad[i]);\n",
        "            break;\n",
        "\n",
        "        default:\n",
        "            new_x = x[i];\n",
        "    }\n",
        "    printf(\"Thread %d, new_x = %f\\n\", i, new_x); // Add printf statement here\n",
        "    x[i] = new_x;\n",
        "}\n",
        "\n",
        "void checkCuda(cudaError_t result, const char *msg) {\n",
        "    if (result != cudaSuccess) {\n",
        "        fprintf(stderr, \"CUDA Error: %s (%s)\\n\", msg, cudaGetErrorString(result));\n",
        "        exit(-1);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float *x, *grad, *d_x, *d_grad;\n",
        "    int mirror_map = NEGATIVE_ENTROPY; // Choose the method\n",
        "\n",
        "    // Allocate memory\n",
        "    x = (float*)malloc(N * sizeof(float));\n",
        "    grad = (float*)malloc(N * sizeof(float));\n",
        "    checkCuda(cudaMalloc(&d_x, N * sizeof(float)), \"Alloc d_x\");\n",
        "    checkCuda(cudaMalloc(&d_grad, N * sizeof(float)), \"Alloc d_grad\");\n",
        "\n",
        "    // Initialize x and grad\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        x[i] = 1.0f;  // Start with x_t = 1\n",
        "        grad[i] = 0.5f * i; // Larger gradient values for visible updates\n",
        "    }\n",
        "\n",
        "    // Copy to GPU\n",
        "    checkCuda(cudaMemcpy(d_x, x, N * sizeof(float), cudaMemcpyHostToDevice), \"Memcpy x -> d_x\");\n",
        "    checkCuda(cudaMemcpy(d_grad, grad, N * sizeof(float), cudaMemcpyHostToDevice), \"Memcpy grad -> d_grad\");\n",
        "\n",
        "    // Kernel execution\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (N + blockSize - 1) / blockSize;\n",
        "    mirror_descent<<<numBlocks, blockSize>>>(d_x, d_grad, ETA, mirror_map, N);\n",
        "    checkCuda(cudaDeviceSynchronize(), \"Kernel execution\");\n",
        "\n",
        "    // Copy results back\n",
        "    checkCuda(cudaMemcpy(x, d_x, N * sizeof(float), cudaMemcpyDeviceToHost), \"Memcpy d_x -> x\");\n",
        "\n",
        "    // Print first 10 results\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        printf(\"x[%d] = %f\\n\", i, x[i]);\n",
        "    }\n",
        "\n",
        "    // Cleanup\n",
        "    free(x);\n",
        "    free(grad);\n",
        "    cudaFree(d_x);\n",
        "    cudaFree(d_grad);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xXp32zRGBgzy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}