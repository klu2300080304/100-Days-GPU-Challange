{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "wZcO0Ehv4KkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-oZpbM03-PU"
      },
      "outputs": [],
      "source": [
        "%%writefile vector_add.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <cmath>\n",
        "#include <random>\n",
        "\n",
        "// Kernel function for SwiGLU\n",
        "__global__ void swiglu_kernel(float* out, const float* x, const float* W1, const float* W2, int batch_size, int hidden_dim, int output_dim) {\n",
        "    int b = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int o = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (b < batch_size && o < output_dim) {\n",
        "        float xW1 = 0.0f;\n",
        "        float xW2 = 0.0f;\n",
        "\n",
        "        for (int i = 0; i < hidden_dim; i++) {\n",
        "            xW1 += x[b * hidden_dim + i] * W1[o + i * output_dim];\n",
        "            xW2 += x[b * hidden_dim + i] * W2[o + i * output_dim];\n",
        "        }\n",
        "\n",
        "        float sigmoid_val = 1.0f / (1.0f + expf(-xW1));\n",
        "        float result = xW1 * sigmoid_val * xW2;\n",
        "\n",
        "        if (b == 0 && o == 0) {  // Debug print for first element\n",
        "            printf(\"GPU Debug: xW1=%f, xW2=%f, sigmoid_val=%f, result=%f\\\\n\",\n",
        "                   xW1, xW2, sigmoid_val, result);\n",
        "        }\n",
        "\n",
        "        out[b * output_dim + o] = result;\n",
        "    }\n",
        "}\n",
        "\n",
        "void swiglu_forward(float* out, const float* x, const float* W1, const float* W2, int batch_size, int hidden_dim, int output_dim) {\n",
        "    float *d_x, *d_W1, *d_W2, *d_out;\n",
        "    cudaMalloc((void**)&d_x, batch_size * hidden_dim * sizeof(float));\n",
        "    cudaMalloc((void**)&d_W1, hidden_dim * output_dim * sizeof(float));\n",
        "    cudaMalloc((void**)&d_W2, hidden_dim * output_dim * sizeof(float));\n",
        "    cudaMalloc((void**)&d_out, batch_size * output_dim * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_x, x, batch_size * hidden_dim * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_W1, W1, hidden_dim * output_dim * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_W2, W2, hidden_dim * output_dim * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 blocksPerGrid((batch_size + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
        "                       (output_dim + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
        "\n",
        "    swiglu_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_out, d_x, d_W1, d_W2, batch_size, hidden_dim, output_dim);\n",
        "\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "        std::cerr << \"Kernel launch failed: \" << cudaGetErrorString(err) << std::endl;\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(out, d_out, batch_size * output_dim * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cudaFree(d_x);\n",
        "    cudaFree(d_W1);\n",
        "    cudaFree(d_W2);\n",
        "    cudaFree(d_out);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int batch_size = 32;\n",
        "    int hidden_dim = 128;\n",
        "    int output_dim = 64;\n",
        "\n",
        "    float *x = new float[batch_size * hidden_dim];\n",
        "    float *W1 = new float[hidden_dim * output_dim];\n",
        "    float *W2 = new float[hidden_dim * output_dim];\n",
        "    float *out = new float[batch_size * output_dim];\n",
        "\n",
        "    std::random_device rd;\n",
        "    std::mt19937 gen(rd());\n",
        "    std::uniform_real_distribution<float> dis(0.0f, 1.0f);\n",
        "\n",
        "    for (int i = 0; i < batch_size * hidden_dim; i++) {\n",
        "        x[i] = dis(gen);\n",
        "    }\n",
        "    for (int i = 0; i < hidden_dim * output_dim; i++) {\n",
        "        W1[i] = dis(gen);\n",
        "        W2[i] = dis(gen);\n",
        "    }\n",
        "\n",
        "    float manual_xW1 = 0.0f;\n",
        "    float manual_xW2 = 0.0f;\n",
        "    for (int i = 0; i < hidden_dim; i++) {\n",
        "        manual_xW1 += x[i] * W1[i * output_dim];\n",
        "        manual_xW2 += x[i] * W2[i * output_dim];\n",
        "    }\n",
        "    std::cout << \"CPU Manual calculation for first element:\" << std::endl;\n",
        "    std::cout << \"xW1: \" << manual_xW1 << std::endl;\n",
        "    std::cout << \"xW2: \" << manual_xW2 << std::endl;\n",
        "    float manual_sigmoid = 1.0f / (1.0f + exp(-manual_xW1));\n",
        "    float manual_result = manual_xW1 * manual_sigmoid * manual_xW2;\n",
        "    std::cout << \"Expected result: \" << manual_result << std::endl;\n",
        "\n",
        "    swiglu_forward(out, x, W1, W2, batch_size, hidden_dim, output_dim);\n",
        "\n",
        "    std::cout << \"\\\\nFirst 10 output values:\" << std::endl;\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        std::cout << \"out[\" << i << \"]: \" << out[i] << std::endl;\n",
        "    }\n",
        "\n",
        "    delete[] x;\n",
        "    delete[] W1;\n",
        "    delete[] W2;\n",
        "    delete[] out;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vector_add.cu -o vector_add -lcudadevrt"
      ],
      "metadata": {
        "id": "S6ABFTof4kYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_add"
      ],
      "metadata": {
        "id": "DbPgnnZ44nsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ADXKPk034rVN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}