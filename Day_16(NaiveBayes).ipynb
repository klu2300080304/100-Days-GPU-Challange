{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRSCLnsT9DtH"
      },
      "outputs": [],
      "source": [
        "%%writefile vector_add.cu\n",
        "\n",
        "// NaiveBayes.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "#include \"NaiveBayesKernel.cuh\"\n",
        "#include \"NaiveBayesTrain.cuh\"\n",
        "\n",
        "#define SHARED_SIZE 20\n",
        "\n",
        "// CUDA Kernel to compute priors (P(Y = c)) and likelihoods (P(X | Y = c)).\n",
        "__global__ void computePriorsAndLikelihood(\n",
        "    int* d_Dataset, int* d_priors, int* d_likelihoods,\n",
        "    int numSamples, int numFeatures, int numClasses, int numFeatureValues\n",
        ") {\n",
        "    int threadId = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    __shared__ int local_d_priors[SHARED_SIZE];\n",
        "    __shared__ int local_d_likelihoods[SHARED_SIZE];\n",
        "\n",
        "    // If the thread is within bounds\n",
        "    if (threadId < numSamples) {\n",
        "        // Each thread processes one data sample\n",
        "        int classLabel = d_Dataset[threadId * (numFeatures + 1) + numFeatures]; // Class label is in the last column\n",
        "\n",
        "        // Atomic update to calculate the prior\n",
        "        atomicAdd(&local_d_priors[classLabel], 1);\n",
        "\n",
        "        // Compute likelihood for each feature\n",
        "        for (int fIdx = 0; fIdx < numFeatures; ++fIdx) {\n",
        "            int featureValue = d_Dataset[threadId * (numFeatures + 1) + fIdx];\n",
        "            int likelihoodIndex = classLabel * numFeatures * numFeatureValues + (fIdx * numFeatureValues) + featureValue;\n",
        "\n",
        "            // Atomic update to the likelihood matrix\n",
        "            atomicAdd(&local_d_likelihoods[likelihoodIndex], 1);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Synchronize threads before writing shared results back to global memory\n",
        "    __syncthreads();\n",
        "\n",
        "    // Write local results to global memory (only one thread needs to do this)\n",
        "    if (threadIdx.x == 0) {\n",
        "        for (int c = 0; c < numClasses; ++c) {\n",
        "            atomicAdd(&d_priors[c], local_d_priors[c]);\n",
        "        }\n",
        "\n",
        "        for (int l = 0; l < numClasses * numFeatures * numFeatureValues; ++l) {\n",
        "            atomicAdd(&d_likelihoods[l], local_d_likelihoods[l]);\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with the specified architecture\n",
        "!nvcc vector_add.cu -o vector_add -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "# Run the executable\n",
        "!./vector_add"
      ],
      "metadata": {
        "id": "F9tvbPv-9W8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TZiJcJOT9ZLt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}