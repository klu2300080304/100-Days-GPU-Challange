{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8mOJJ8aX_4q"
      },
      "outputs": [],
      "source": [
        "%%writefile vector_add.cu\n",
        "\n",
        "// use this command: nvcc -o fcnet fcnet.cu -lcudnn -lcublas -lcurand\n",
        "\n",
        "#include <cudnn.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <curand.h>\n",
        "#include <cstdlib>\n",
        "#include <ctime>\n",
        "#include <iostream>\n",
        "\n",
        "#define CHECK_CUDA(func) { \\\n",
        "    cudaError_t status = (func); \\\n",
        "    if (status != cudaSuccess) { \\\n",
        "        std::cerr << \"CUDA Error at \" << __FILE__ << \":\" << __LINE__ << \" - \" << cudaGetErrorString(status) << std::endl; \\\n",
        "        exit(EXIT_FAILURE); \\\n",
        "    } \\\n",
        "}\n",
        "\n",
        "#define CHECK_CUDNN(func) { \\\n",
        "    cudnnStatus_t status = (func); \\\n",
        "    if (status != CUDNN_STATUS_SUCCESS) { \\\n",
        "        std::cerr << \"cuDNN Error at \" << __FILE__ << \":\" << __LINE__ << \" - \" << cudnnGetErrorString(status) << std::endl; \\\n",
        "        exit(EXIT_FAILURE); \\\n",
        "    } \\\n",
        "}\n",
        "\n",
        "// Network parameters\n",
        "const int input_size = 1000;\n",
        "const int hidden_size = 512;\n",
        "const int output_size = 10;\n",
        "const int batch_size = 64;\n",
        "const float learning_rate = 0.001f;\n",
        "const int epochs = 10;\n",
        "\n",
        "// Helper function to initialize weights\n",
        "void initialize_weights(float* weights, int size) {\n",
        "    curandGenerator_t gen;\n",
        "    curandCreateGenerator(&gen, CURAND_RNG_PSEUDO_DEFAULT);\n",
        "    curandSetPseudoRandomGeneratorSeed(gen, time(NULL));\n",
        "    curandGenerateUniform(gen, weights, size);\n",
        "    curandDestroyGenerator(gen);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"Starting main function...\\n\"); // Added printf\n",
        "\n",
        "    // Initialize CUDA and cuDNN\n",
        "    cudnnHandle_t cudnn;\n",
        "    CHECK_CUDNN(cudnnCreate(&cudnn));\n",
        "    printf(\"cuDNN initialized.\\n\"); // Added printf\n",
        "\n",
        "    // Create tensor descriptors\n",
        "    cudnnTensorDescriptor_t input_desc, hidden1_desc, hidden2_desc, output_desc;\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&input_desc));\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&hidden1_desc));\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&hidden2_desc));\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&output_desc));\n",
        "    printf(\"Tensor descriptors created.\\n\"); // Added printf\n",
        "\n",
        "    // Set tensor dimensions (NCHW format)\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT,\n",
        "                                          batch_size, input_size, 1, 1));\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(hidden1_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT,\n",
        "                                          batch_size, hidden_size, 1, 1));\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(hidden2_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT,\n",
        "                                          batch_size, hidden_size, 1, 1));\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT,\n",
        "                                          batch_size, output_size, 1, 1));\n",
        "    printf(\"Tensor descriptors set.\\n\"); // Added printf\n",
        "\n",
        "    // Create filter descriptors (weights)\n",
        "    cudnnFilterDescriptor_t fc1_w_desc, fc2_w_desc, fc3_w_desc;\n",
        "    CHECK_CUDNN(cudnnCreateFilterDescriptor(&fc1_w_desc));\n",
        "    CHECK_CUDNN(cudnnSetFilter4dDescriptor(fc1_w_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW,\n",
        "                                          hidden_size, input_size, 1, 1));\n",
        "\n",
        "    CHECK_CUDNN(cudnnCreateFilterDescriptor(&fc2_w_desc));\n",
        "    CHECK_CUDNN(cudnnSetFilter4dDescriptor(fc2_w_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW,\n",
        "                                          hidden_size, hidden_size, 1, 1));\n",
        "\n",
        "    CHECK_CUDNN(cudnnCreateFilterDescriptor(&fc3_w_desc));\n",
        "    CHECK_CUDNN(cudnnSetFilter4dDescriptor(fc3_w_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW,\n",
        "                                          output_size, hidden_size, 1, 1));\n",
        "    printf(\"Filter descriptors created and set.\\n\"); // Added printf\n",
        "\n",
        "\n",
        "    // Create activation descriptor (ReLU)\n",
        "    cudnnActivationDescriptor_t relu_desc;\n",
        "    CHECK_CUDNN(cudnnCreateActivationDescriptor(&relu_desc));\n",
        "    CHECK_CUDNN(cudnnSetActivationDescriptor(relu_desc, CUDNN_ACTIVATION_RELU,\n",
        "                                             CUDNN_NOT_PROPAGATE_NAN, 0.0));\n",
        "    printf(\"Activation descriptor created and set.\\n\"); // Added printf\n",
        "\n",
        "\n",
        "    // Allocate device memory\n",
        "    float *d_input, *d_labels, *d_output;\n",
        "    CHECK_CUDA(cudaMalloc(&d_input, batch_size * input_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMalloc(&d_labels, batch_size * output_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMalloc(&d_output, batch_size * output_size * sizeof(float)));\n",
        "    printf(\"Device memory allocated for input, labels, and output.\\n\"); // Added printf\n",
        "\n",
        "\n",
        "    // Initialize weights and biases\n",
        "    float *d_w1, *d_b1, *d_w2, *d_b2, *d_w3, *d_b3;\n",
        "    CHECK_CUDA(cudaMalloc(&d_w1, hidden_size * input_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMalloc(&d_b1, hidden_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMalloc(&d_w2, hidden_size * hidden_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMalloc(&d_b2, hidden_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMalloc(&d_w3, output_size * hidden_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMalloc(&d_b3, output_size * sizeof(float)));\n",
        "\n",
        "    initialize_weights(d_w1, hidden_size * input_size);\n",
        "    initialize_weights(d_w2, hidden_size * hidden_size);\n",
        "    initialize_weights(d_w3, output_size * hidden_size);\n",
        "    CHECK_CUDA(cudaMemset(d_b1, 0, hidden_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMemset(d_b2, 0, hidden_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMemset(d_b3, 0, output_size * sizeof(float)));\n",
        "    printf(\"Weights and biases allocated and initialized.\\n\"); // Added printf\n",
        "\n",
        "\n",
        "    // Generate dummy data\n",
        "    initialize_weights(d_input, batch_size * input_size);\n",
        "    initialize_weights(d_labels, batch_size * output_size);\n",
        "    printf(\"Dummy data generated.\\n\"); // Added printf\n",
        "\n",
        "\n",
        "    // Create convolution descriptors\n",
        "    cudnnConvolutionDescriptor_t conv_desc;\n",
        "    CHECK_CUDNN(cudnnCreateConvolutionDescriptor(&conv_desc));\n",
        "    CHECK_CUDNN(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1,\n",
        "                                               CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));\n",
        "    printf(\"Convolution descriptor created and set.\\n\"); // Added printf\n",
        "\n",
        "\n",
        "    // Training loop\n",
        "    for (int epoch = 0; epoch < epochs; ++epoch) {\n",
        "        printf(\"Epoch %d started.\\n\", epoch); // Added printf\n",
        "\n",
        "        // Forward pass\n",
        "        float alpha = 1.0f, beta = 0.0f;\n",
        "        float* d_hidden1, *d_hidden2;\n",
        "        CHECK_CUDA(cudaMalloc(&d_hidden1, batch_size * hidden_size * sizeof(float)));\n",
        "        CHECK_CUDA(cudaMalloc(&d_hidden2, batch_size * hidden_size * sizeof(float)));\n",
        "        printf(\"Intermediate hidden layers allocated.\\n\"); // Added printf\n",
        "\n",
        "\n",
        "        // Layer 1: Input -> Hidden1\n",
        "        CHECK_CUDNN(cudnnConvolutionForward(cudnn, &alpha,\n",
        "                                           input_desc, d_input,\n",
        "                                           fc1_w_desc, d_w1,\n",
        "                                           conv_desc,\n",
        "                                           CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM,\n",
        "                                           nullptr, 0,\n",
        "                                           &beta,\n",
        "                                           hidden1_desc, d_hidden1));\n",
        "        CHECK_CUDNN(cudnnAddTensor(cudnn, &alpha, hidden1_desc, d_b1,\n",
        "                                  &alpha, hidden1_desc, d_hidden1));\n",
        "        CHECK_CUDNN(cudnnActivationForward(cudnn, relu_desc,\n",
        "                                          &alpha, hidden1_desc, d_hidden1,\n",
        "                                          &beta, hidden1_desc, d_hidden1));\n",
        "        printf(\"Layer 1 forward pass completed.\\n\"); // Added printf\n",
        "\n",
        "        // Layer 2: Hidden1 -> Hidden2\n",
        "        CHECK_CUDNN(cudnnConvolutionForward(cudnn, &alpha,\n",
        "                                           hidden1_desc, d_hidden1,\n",
        "                                           fc2_w_desc, d_w2,\n",
        "                                           conv_desc,\n",
        "                                           CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM,\n",
        "                                           nullptr, 0,\n",
        "                                           &beta,\n",
        "                                           hidden2_desc, d_hidden2));\n",
        "        CHECK_CUDNN(cudnnAddTensor(cudnn, &alpha, hidden2_desc, d_b2,\n",
        "                                  &alpha, hidden2_desc, d_hidden2));\n",
        "        CHECK_CUDNN(cudnnActivationForward(cudnn, relu_desc,\n",
        "                                          &alpha, hidden2_desc, d_hidden2,\n",
        "                                          &beta, hidden2_desc, d_hidden2));\n",
        "        printf(\"Layer 2 forward pass completed.\\n\"); // Added printf\n",
        "\n",
        "\n",
        "        // Layer 3: Hidden2 -> Output\n",
        "        CHECK_CUDNN(cudnnConvolutionForward(cudnn, &alpha,\n",
        "                                           hidden2_desc, d_hidden2,\n",
        "                                           fc3_w_desc, d_w3,\n",
        "                                           conv_desc,\n",
        "                                           CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM,\n",
        "                                           nullptr, 0,\n",
        "                                           &beta,\n",
        "                                           output_desc, d_output));\n",
        "        CHECK_CUDNN(cudnnAddTensor(cudnn, &alpha, output_desc, d_b3,\n",
        "                                  &alpha, output_desc, d_output));\n",
        "        printf(\"Layer 3 forward pass completed.\\n\"); // Added printf\n",
        "\n",
        "\n",
        "        // Cleanup intermediate buffers\n",
        "        CHECK_CUDA(cudaFree(d_hidden1));\n",
        "        CHECK_CUDA(cudaFree(d_hidden2));\n",
        "        printf(\"Intermediate buffers freed.\\n\"); // Added printf\n",
        "\n",
        "\n",
        "        // Inference (example)\n",
        "        if (epoch == epochs - 1) {\n",
        "            float* h_output = new float[batch_size * output_size];\n",
        "            CHECK_CUDA(cudaMemcpy(h_output, d_output, batch_size * output_size * sizeof(float),\n",
        "                                 cudaMemcpyDeviceToHost));\n",
        "            std::cout << \"Final inference results sample: \" << h_output[0] << std::endl;\n",
        "            delete[] h_output;\n",
        "        }\n",
        "        printf(\"Epoch %d finished.\\n\", epoch); // Added printf\n",
        "\n",
        "    }\n",
        "\n",
        "    // Cleanup\n",
        "    CHECK_CUDA(cudaFree(d_input));\n",
        "    CHECK_CUDA(cudaFree(d_labels));\n",
        "    CHECK_CUDA(cudaFree(d_output));\n",
        "    CHECK_CUDA(cudaFree(d_w1));\n",
        "    CHECK_CUDA(cudaFree(d_b1));\n",
        "    CHECK_CUDA(cudaFree(d_w2));\n",
        "    CHECK_CUDA(cudaFree(d_b2));\n",
        "    CHECK_CUDA(cudaFree(d_w3));\n",
        "    CHECK_CUDA(cudaFree(d_b3));\n",
        "    printf(\"Device memory freed.\\n\"); // Added printf\n",
        "\n",
        "\n",
        "    CHECK_CUDNN(cudnnDestroyConvolutionDescriptor(conv_desc));\n",
        "    CHECK_CUDNN(cudnnDestroyActivationDescriptor(relu_desc));\n",
        "    CHECK_CUDNN(cudnnDestroyFilterDescriptor(fc1_w_desc));\n",
        "    CHECK_CUDNN(cudnnDestroyFilterDescriptor(fc2_w_desc));\n",
        "    CHECK_CUDNN(cudnnDestroyFilterDescriptor(fc3_w_desc));\n",
        "    CHECK_CUDNN(cudnnDestroyTensorDescriptor(input_desc));\n",
        "    CHECK_CUDNN(cudnnDestroyTensorDescriptor(hidden1_desc));\n",
        "    CHECK_CUDNN(cudnnDestroyTensorDescriptor(hidden2_desc));\n",
        "    CHECK_CUDNN(cudnnDestroyTensorDescriptor(output_desc));\n",
        "    CHECK_CUDNN(cudnnDestroy(cudnn));\n",
        "    printf(\"cuDNN resources destroyed.\\n\"); // Added printf\n",
        "\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with the specified architecture\n",
        "!nvcc vector_add.cu -o vector_add -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "# Run the executable\n",
        "!./vector_add"
      ],
      "metadata": {
        "id": "RRFEP7trYVuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OKzRgRfeYYKx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}