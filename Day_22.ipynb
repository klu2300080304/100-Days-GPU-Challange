{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "SdldiOS32rkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cu\n",
        "#include <iostream>\n",
        "#include <cmath>\n",
        "#include <cstdlib>\n",
        "#include <ctime>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#ifndef M_PI\n",
        "#define M_PI 3.14159265358979323846\n",
        "#endif\n",
        "\n",
        "#define NUM_CLUSTERS 2\n",
        "#define N 1024\n",
        "#define THREADS_PER_BLOCK 256\n",
        "\n",
        "#define CUDA_CHECK(call) \\\n",
        "    do { \\\n",
        "        cudaError_t error = call; \\\n",
        "        if (error != cudaSuccess) { \\\n",
        "            std::cerr << \"CUDA Error: \" << cudaGetErrorString(error) \\\n",
        "                      << \" at \" << __FILE__ << \":\" << __LINE__ << std::endl; \\\n",
        "            exit(EXIT_FAILURE); \\\n",
        "        } \\\n",
        "    } while (0)\n",
        "\n",
        "__global__ void eStepKernel(float* data, int N, float* mu, float* sigma,\n",
        "                           float* pival, float* responsibilities) {\n",
        "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (idx < N) {\n",
        "        float x = data[idx];\n",
        "        float probs[NUM_CLUSTERS];\n",
        "        float sum = 0.0f;\n",
        "\n",
        "        for (int k = 0; k < NUM_CLUSTERS; k++) {\n",
        "            float diff = x - mu[k];\n",
        "            float exponent = -0.5f * (diff * diff) / (sigma[k] * sigma[k]);\n",
        "            float gauss = (1.0f / (sqrtf(2.0f * M_PI) * sigma[k])) * expf(exponent);\n",
        "            probs[k] = pival[k] * gauss;\n",
        "            sum += probs[k];\n",
        "        }\n",
        "\n",
        "        for (int k = 0; k < NUM_CLUSTERS; k++) {\n",
        "            responsibilities[idx * NUM_CLUSTERS + k] = probs[k] / sum;\n",
        "        }\n",
        "\n",
        "        if (idx == 0) {\n",
        "            printf(\"Data point %d: x = %f, responsibility for cluster 0 = %f\\n\",\n",
        "                   idx, x, responsibilities[idx * NUM_CLUSTERS + 0]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void mStepKernel(float* data, int N, float* responsibilities,\n",
        "                           float* sum_gamma, float* sum_x, float* sum_x2) {\n",
        "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (idx < N) {\n",
        "        float x = data[idx];\n",
        "        for (int k = 0; k < NUM_CLUSTERS; k++) {\n",
        "            float gamma = responsibilities[idx * NUM_CLUSTERS + k];\n",
        "            atomicAdd(&sum_gamma[k], gamma);\n",
        "            atomicAdd(&sum_x[k], gamma * x);\n",
        "            atomicAdd(&sum_x2[k], gamma * x * x);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    srand(static_cast<unsigned>(time(NULL)));\n",
        "\n",
        "    float h_data[N];\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        if (i < N/2) h_data[i] = 2.0f + static_cast<float>(rand()) / RAND_MAX;\n",
        "        else h_data[i] = 8.0f + static_cast<float>(rand()) / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    float h_mu[NUM_CLUSTERS] = {1.0f, 9.0f};\n",
        "    float h_sigma[NUM_CLUSTERS] = {1.0f, 1.0f};\n",
        "    float h_pival[NUM_CLUSTERS] = {0.5f, 0.5f};\n",
        "\n",
        "    float *d_data, *d_mu, *d_sigma, *d_pival;\n",
        "    float *d_responsibilities, *d_sum_gamma, *d_sum_x, *d_sum_x2;\n",
        "\n",
        "    CUDA_CHECK(cudaMalloc(&d_data, N * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_mu, NUM_CLUSTERS * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_sigma, NUM_CLUSTERS * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_pival, NUM_CLUSTERS * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_responsibilities, N * NUM_CLUSTERS * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_sum_gamma, NUM_CLUSTERS * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_sum_x, NUM_CLUSTERS * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_sum_x2, NUM_CLUSTERS * sizeof(float)));\n",
        "\n",
        "    CUDA_CHECK(cudaMemcpy(d_data, h_data, N * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_mu, h_mu, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_sigma, h_sigma, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_pival, h_pival, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    int blocks = (N + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n",
        "\n",
        "    float h_sum_gamma[NUM_CLUSTERS];\n",
        "    float h_sum_x[NUM_CLUSTERS];\n",
        "    float h_sum_x2[NUM_CLUSTERS];\n",
        "\n",
        "    int maxIter = 100;\n",
        "    for (int iter = 0; iter < maxIter; iter++) {\n",
        "        eStepKernel<<<blocks, THREADS_PER_BLOCK>>>(d_data, N, d_mu, d_sigma,\n",
        "                                                  d_pival, d_responsibilities);\n",
        "        CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "        CUDA_CHECK(cudaMemset(d_sum_gamma, 0, NUM_CLUSTERS * sizeof(float)));\n",
        "        CUDA_CHECK(cudaMemset(d_sum_x, 0, NUM_CLUSTERS * sizeof(float)));\n",
        "        CUDA_CHECK(cudaMemset(d_sum_x2, 0, NUM_CLUSTERS * sizeof(float)));\n",
        "\n",
        "        mStepKernel<<<blocks, THREADS_PER_BLOCK>>>(d_data, N, d_responsibilities,\n",
        "                                                  d_sum_gamma, d_sum_x, d_sum_x2);\n",
        "        CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "        CUDA_CHECK(cudaMemcpy(h_sum_gamma, d_sum_gamma, NUM_CLUSTERS * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "        CUDA_CHECK(cudaMemcpy(h_sum_x, d_sum_x, NUM_CLUSTERS * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "        CUDA_CHECK(cudaMemcpy(h_sum_x2, d_sum_x2, NUM_CLUSTERS * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "\n",
        "        for (int k = 0; k < NUM_CLUSTERS; k++) {\n",
        "            if (h_sum_gamma[k] > 1e-6f) {\n",
        "                h_mu[k] = h_sum_x[k] / h_sum_gamma[k];\n",
        "                float variance = h_sum_x2[k] / h_sum_gamma[k] - h_mu[k] * h_mu[k];\n",
        "                h_sigma[k] = sqrtf(fmax(variance, 1e-6f));\n",
        "                h_pival[k] = h_sum_gamma[k] / N;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        CUDA_CHECK(cudaMemcpy(d_mu, h_mu, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
        "        CUDA_CHECK(cudaMemcpy(d_sigma, h_sigma, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
        "        CUDA_CHECK(cudaMemcpy(d_pival, h_pival, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "        if (iter % 10 == 0) {\n",
        "            std::cout << \"Iteration \" << iter << \":\\n\";\n",
        "            for (int k = 0; k < NUM_CLUSTERS; k++) {\n",
        "                std::cout << \"Cluster \" << k << \": \"\n",
        "                         << \"mu = \" << h_mu[k] << \", \"\n",
        "                         << \"sigma = \" << h_sigma[k] << \", \"\n",
        "                         << \"pi = \" << h_pival[k] << std::endl;\n",
        "            }\n",
        "            std::cout << std::endl;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    cudaFree(d_data);\n",
        "    cudaFree(d_mu);\n",
        "    cudaFree(d_sigma);\n",
        "    cudaFree(d_pival);\n",
        "    cudaFree(d_responsibilities);\n",
        "    cudaFree(d_sum_gamma);\n",
        "    cudaFree(d_sum_x);\n",
        "    cudaFree(d_sum_x2);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "8Sjq0upe3aoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Do7NfITG3u5_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}