{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0153873d",
        "outputId": "e51c6363-8f98-46a9-fe3f-8c8f3dff5162"
      },
      "source": [
        "%%writefile vector_add.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "// Macro for checking CUDA errors\n",
        "#define CUDA_CHECK(call) \\\n",
        "    { \\\n",
        "        const cudaError_t error = call; \\\n",
        "        if (error != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__); \\\n",
        "            fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(error)); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    }\n",
        "\n",
        "__global__ void vectorAdd(const float* A, const float* B, float* C, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < N) {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 10;\n",
        "    float A[N], B[N], C[N];\n",
        "\n",
        "    // Initialize vectors A and B\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        A[i] = i * 1.0f;\n",
        "        B[i] = i * 2.0f;\n",
        "    }\n",
        "\n",
        "    float *d_a, *d_b,*d_c;\n",
        "    CUDA_CHECK(cudaMalloc(&d_a,N*sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_b,N*sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_c,N*sizeof(float)));\n",
        "    CUDA_CHECK(cudaMemcpy(d_a,A,N*sizeof(float),cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_b,B,N*sizeof(float),cudaMemcpyHostToDevice));\n",
        "\n",
        "    // --- Debugging: Print device memory before kernel launch ---\n",
        "    float h_a_debug[N], h_b_debug[N], h_c_debug_before[N];\n",
        "    CUDA_CHECK(cudaMemcpy(h_a_debug, d_a, N*sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    CUDA_CHECK(cudaMemcpy(h_b_debug, d_b, N*sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    CUDA_CHECK(cudaMemcpy(h_c_debug_before, d_c, N*sizeof(float), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    std::cout << \"Device A before kernel: \";\n",
        "    for(int i=0; i<N; ++i) std::cout << h_a_debug[i] << \" \";\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    std::cout << \"Device B before kernel: \";\n",
        "    for(int i=0; i<N; ++i) std::cout << h_b_debug[i] << \" \";\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    std::cout << \"Device C before kernel: \";\n",
        "    for(int i=0; i<N; ++i) std::cout << h_c_debug_before[i] << \" \";\n",
        "    std::cout << std::endl;\n",
        "    // --- End Debugging ---\n",
        "\n",
        "\n",
        "    int blocksize=256;\n",
        "    int gridsize=(int)ceil((float)N/blocksize); // Cast to float for ceil function\n",
        "    vectorAdd<<<gridsize,blocksize>>>(d_a,d_b,d_c,N);\n",
        "    CUDA_CHECK(cudaGetLastError()); // Check for launch errors\n",
        "    CUDA_CHECK(cudaDeviceSynchronize()); // Add synchronization here\n",
        "\n",
        "    CUDA_CHECK(cudaMemcpy(C,d_c,N*sizeof(float),cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Print the final result\n",
        "    std::cout << \"Final result of vector addition:\" << std::endl;\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        std::cout << C[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    CUDA_CHECK(cudaFree(d_a));\n",
        "    CUDA_CHECK(cudaFree(d_b));\n",
        "    CUDA_CHECK(cudaFree(d_c));\n",
        "\n",
        "    return 0; // Add return statement to main\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3daabc92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb11daa9-b17e-4ffd-b163-0de78597c969"
      },
      "source": [
        "# Compile with the specified architecture\n",
        "!nvcc vector_add.cu -o vector_add -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "# Run the executable\n",
        "!./vector_add"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device A before kernel: 0 1 2 3 4 5 6 7 8 9 \n",
            "Device B before kernel: 0 2 4 6 8 10 12 14 16 18 \n",
            "Device C before kernel: 0 0 0 0 0 0 0 0 0 0 \n",
            "Final result of vector addition:\n",
            "0 3 6 9 12 15 18 21 24 27 \n"
          ]
        }
      ]
    }
  ]
}