{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSvb6KJb72lJ"
      },
      "outputs": [],
      "source": [
        "%%writefile vector_add.cu\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#include <math.h>\n",
        "#include \"kernels.cuh\"\n",
        "\n",
        "\n",
        "__global__ void computeDKernel(const float* dO, const float* O, float* D, int N, int d) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx >= N) return;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "    for (int i = 0; i < d; i++) {\n",
        "        sum += dO[idx * d + i] * O[idx * d + i];\n",
        "    }\n",
        "    D[idx] = sum;\n",
        "}\n",
        "\n",
        "__global__ void computeSiKernel(const float* Qi, const float* Kj, float* Si, int Br, int Bc, int d, float scale) {\n",
        "    int row = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (row >= Br) return;\n",
        "\n",
        "    for (int col = 0; col < Bc; ++col) {\n",
        "        float sum = 0.0f;\n",
        "        for (int k = 0; k < d; ++k) {\n",
        "            sum += Qi[row * d + k] * Kj[col * d + k];\n",
        "        }\n",
        "        Si[row * Bc + col] = sum * scale; // Apply scaling here\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void findRowMaxSiKernel(const float* Si, float* maxSi, int Br, int Bc) {\n",
        "    int row = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (row >= Br) return;\n",
        "\n",
        "    __shared__ float shared_max[BLOCK_SIZE];\n",
        "    float local_max = NEGATIVE_INFINITY;\n",
        "\n",
        "    for (int col = threadIdx.x; col < Bc; col += blockDim.x) {\n",
        "        local_max = fmaxf(local_max, Si[row * Bc + col]);\n",
        "    }\n",
        "\n",
        "    shared_max[threadIdx.x] = local_max;\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
        "        if (threadIdx.x < s) {\n",
        "            shared_max[threadIdx.x] = fmaxf(shared_max[threadIdx.x], shared_max[threadIdx.x + s]);\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (threadIdx.x == 0) {\n",
        "        maxSi[row] = shared_max[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void computePiKernel(const float* Si, const float* Li, float* Pi, int Br, int Bc, const float* maxSi) {\n",
        "    int row = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int col = threadIdx.x;\n",
        "    if (row >= Br) return;\n",
        "\n",
        "    __shared__ float shared_max[BLOCK_SIZE];\n",
        "     if (col < Bc) {\n",
        "         float si_val = Si[row * Bc + col];\n",
        "         float li_val = Li[row];\n",
        "         float max_si_val = maxSi[row];\n",
        "         float val = expf(si_val - li_val - max_si_val);\n",
        "         if (isnan(val) || isinf(val)) {\n",
        "             val = 0.0f;\n",
        "         }\n",
        "         Pi[row * Bc + col] = val;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void computeDViKernel(const float* Pi, const float* dOi, float* dVj_temp, int Br, int Bc, int d) {\n",
        "    int col_dVi = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (col_dVi >= d) return;\n",
        "\n",
        "    for (int row_dVj = 0; row_dVj < Bc; ++row_dVj) {\n",
        "        float sum = 0.0f;\n",
        "        for (int row_Pi = 0; row_Pi < Br; ++row_Pi) {\n",
        "            sum += Pi[row_Pi * Bc + row_dVj] * dOi[row_Pi * d + col_dVi];\n",
        "        }\n",
        "        dVj_temp[row_dVj * d + col_dVi] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void computeDPiKernel(const float* dOi, const float* Vj, float* dPi, int Br, int Bc, int d) {\n",
        "    int row = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (row >= Br) return;\n",
        "\n",
        "    for (int col = 0; col < Bc; ++col) {\n",
        "        float sum = 0.0f;\n",
        "        for (int k = 0; k < d; ++k) {\n",
        "            sum += dOi[row * d + k] * Vj[col * d + k];\n",
        "        }\n",
        "        dPi[row * Bc + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void computeDSiKernel(const float* Pi, const float* dPi, const float* Di, float* dSi, int Br, int Bc) {\n",
        "    int row = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int col = threadIdx.x;\n",
        "\n",
        "    if (row >= Br || col >= Bc) return;\n",
        "    __shared__ float shared_di[BLOCK_SIZE];\n",
        "     if(threadIdx.x < Bc) {\n",
        "         shared_di[threadIdx.x] = Di[row]; // Load each element of Di\n",
        "     }\n",
        "     __syncthreads();\n",
        "    dSi[row * Bc + col] = Pi[row * Bc + col] * (dPi[row * Bc + col] - shared_di[threadIdx.x]);\n",
        "}\n",
        "\n",
        "__global__ void computeDQiKernel(const float* dSi, const float* Kj, float* dQi_temp, int Br, int d, int Bc) {\n",
        "    int row = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (row >= Br) return;\n",
        "\n",
        "    for (int col = 0; col < d; ++col) {\n",
        "        float sum = 0.0f;\n",
        "        for (int k = 0; k < Bc; ++k) {\n",
        "            sum += dSi[row * Bc + k] * Kj[k * d + col];\n",
        "        }\n",
        "        dQi_temp[row * d + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void computeDKjKernel(const float* dSi, const float* Qi, float* dKj_temp, int Bc, int d, int Br) {\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (col >= Bc) return;\n",
        "\n",
        "    for (int row = 0; row < d; ++row) {\n",
        "        float sum = 0.0f;\n",
        "        for (int k = 0; k < Br; ++k) {\n",
        "            sum += dSi[k * Bc + col] * Qi[k * d + row];\n",
        "        }\n",
        "        dKj_temp[col * d + row] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void accumulateDQKernel(float* dQ, const float* dQi_temp, int Br, int d, int globalOffset) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx >= Br * d) return;\n",
        "\n",
        "    atomicAdd(&dQ[globalOffset + idx], dQi_temp[idx]);\n",
        "}\n",
        "\n",
        "__global__ void accumulateDKVjKernel(float* dK, float* dV, const float* dKj_temp, const float* dVj_temp, int Bc, int d, int globalOffset) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx >= Bc * d) return;\n",
        "\n",
        "    atomicAdd(&dK[globalOffset + idx], dKj_temp[idx]);\n",
        "    atomicAdd(&dV[globalOffset + idx], dVj_temp[idx]);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with the specified architecture\n",
        "!nvcc vector_add.cu -o vector_add -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "# Run the executable\n",
        "!./vector_add"
      ],
      "metadata": {
        "id": "A5C7kiMc8CXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RUR8VpCv8E7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa186637"
      },
      "source": [
        "%%writefile kernels.cuh\n",
        "#ifndef KERNELS_CUH\n",
        "#define KERNELS_CUH\n",
        "\n",
        "#define BLOCK_SIZE 256\n",
        "#define NEGATIVE_INFINITY -1e38f // A sufficiently small negative number\n",
        "\n",
        "#endif // KERNELS_CUH"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}